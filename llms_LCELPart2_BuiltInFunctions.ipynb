{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6858fd0a",
   "metadata": {},
   "source": [
    "LCEL -> Built-In Functions\n",
    "\n",
    "1. Runnable PassThrough (Pass through - no changes in that - pass same thing without changing)\n",
    "2. Runnable Parallel (Multiple seq of chain)\n",
    "3. Runnable Lambda (Custom Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c21102",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "295b0bed",
   "metadata": {},
   "source": [
    "1. Runnable PassThrough\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3925af39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "llm_model = ChatGroq(\n",
    "    groq_api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    "    model_name=\"llama3-70b-8192\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f130f419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prince'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = RunnablePassthrough()\n",
    "chain.invoke('prince')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb42095d",
   "metadata": {},
   "source": [
    "2. Runnable Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "037d2df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e02f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname(name : str) -> str:\n",
    "    return f\"{name}ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973db129",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough() | RunnableLambda(russian_lastname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc0f36db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MahimaShettyovich'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"MahimaShetty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a265e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def russian_lastname_dict(input_dict: dict) -> str:\n",
    "    name = input_dict[\"name\"]\n",
    "    return f\"{name}ovich\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcd18d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough() | RunnableLambda(russian_lastname_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59406334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MahimaShettyovich'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"name\":\"MahimaShetty\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3937cf84",
   "metadata": {},
   "source": [
    "3. Runnable Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc2ec644",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "chain = RunnableParallel(\n",
    "    {\"operation_a\" : RunnablePassthrough(),\n",
    "    \"operation_b\" : RunnableLambda(russian_lastname)}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c7fb08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'operation_a': 'Mahima', 'operation_b': 'Mahimaovich'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Mahima\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa70ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    (\"tell me a curious fact about {soccer_player}\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a761373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25ab5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(\n",
    "    {\"operation_a\" : RunnablePassthrough(),\n",
    "     \"soccer_player\" : RunnableLambda(russian_lastname_dict),\n",
    "     \"operation_c\": RunnablePassthrough()}\n",
    ") | prompt | llm_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89676505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I apologize, but I couldn't find any information on a person named MahimaShettyovich. It's possible that this person is not a public figure or doesn't have a significant online presence. Can I assist you with something else?\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"name\":\"MahimaShetty\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a3f67c",
   "metadata": {},
   "source": [
    "Retrieval Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "164e5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5afc8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\msshe\\AppData\\Local\\Temp\\ipykernel_13916\\687389532.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n",
      "c:\\Users\\msshe\\Documents\\Projects\\Demo-Langchain\\langchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"  # Small, fast, reliable\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "87b9ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_texts([\"learning logic focus on providing Data science, AI, DL, CV, Python\"], embedding = embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "56565cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "34df0415",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\" Answer the question based only on the following content {context}   Question : {question}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "94d4876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6fc884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_chain = RunnableParallel({\"context\": retriever, \"question\": RunnablePassthrough()}) | prompt | llm_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7e8842f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There is no information about Harrison or where he worked in the provided content. The content only mentions \"learning logic\" and lists some topics like Data Science, AI, DL, CV, and Python, but it does not mention Harrison or any person\\'s workplace.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain.invoke(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff72679",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
